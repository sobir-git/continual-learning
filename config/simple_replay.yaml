dataset: CIFAR100
n_phases: 10
n_classes_per_phase: 10
memory_size: 2000
val_size: 0.1
batch_size: 64
batch_memory_samples: 32
epochs: 100
lr: 0.01
min_init_lr: 0.0001
min_lr: 0.00001
model: efficientnet-b0
pretrained: true  # use pretrained model
split_pos: -3  # place where to split pretrained model into feature extractor and head
split_pos_lower: null
resize_input: 224
download: true
torch:
  num_workers: 3
  pin_memory: true
  non_blocking: true
  drop_last: false
datadir: ../data
class_order_seed: -1
lr_scheduler: exp
lr_step_size: 1
gamma: 0.95
global_gamma: 0.8
lr_patience: 5  # number of epochs without improvement before lr is reduced (multiplied by gamma)
epochs_tol: 15
phase: null  # run only a specific phase
reset_weights: 'output'  # reset weights before each phase; choices: 'none', 'output', 'all'
faster_output_learning_rate: false  # use higher learning rate (x10) for the output layer
val_metric: loss
method: gdumb
bic: false
bic_lr: 0.01
bic_epochs: 10
input_size: [ 3, 224, 224 ]
